{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BOSH Bootloader Also known as bbl (pronounced: \"bubble\") , bosh-bootloader is a command line utility for standing up a CloudFoundry or Concourse installation on an IaaS. bbl currently supports AWS, GCP, Microsoft Azure, Openstack and vSphere. CI Tracker What bbl does Generate terraform template The first step that bbl up does is to generate a Terraform template based on your IAAS, IAAS region, and chosen load balancer type (or lack thereof). The resulting Terraform template is emitted to the terraform/bbl-template.tf file within your state directory. Apply terraform template After generating the Terraform template, bbl up will run Terraform to apply that template, using also a variables file located at vars/bbl.tfvars within the state directory. Map terraform outputs to BOSH create-env vars Having applied the Terraform template, we now have a number of Terraform outputs, such as subnet CIDRs, reserved IP addresses, and load balancer configuration. bbl will transform those outputs into the inputs required by jumpbox-deployment and bosh-deployment and write them to the files vars/jumpbox-vars-file.yml and vars/director-vars-file.yml . Execute BOSH create-env (jumpbox, director) Next, bbl shells out to the BOSH CLI to run bosh create-env twice. The first time, bbl uses jumpbox-deployment and creates the jumpbox vm; the second time, bbl uses bosh-deployment and creates the director VM. The exact commands that bbl will run are emitted to the create-jumpbox.sh and create-director.sh files within the state directory. Generate cloud-config template After the director VM comes up, bbl generates a base cloud-config, based on the IAAS, IAAS region, and chosen load balancer type. Map Terraform outputs to BOSH cloud-config vars Having generated a base cloud-config template, bbl maps Terraform outputs to cloud-config variables. These variables include network and subnetwork names, security groups or tags, and CIDR ranges, as well as load balancer target pool names. Update cloud-config (director) Finally, bbl will update the director's cloud config, by shelling out to bosh update-cloud-config .","title":"BOSH Bootloader"},{"location":"#bosh-bootloader","text":"Also known as bbl (pronounced: \"bubble\") , bosh-bootloader is a command line utility for standing up a CloudFoundry or Concourse installation on an IaaS. bbl currently supports AWS, GCP, Microsoft Azure, Openstack and vSphere. CI Tracker","title":"BOSH Bootloader"},{"location":"#what-bbl-does","text":"","title":"What bbl does"},{"location":"#generate-terraform-template","text":"The first step that bbl up does is to generate a Terraform template based on your IAAS, IAAS region, and chosen load balancer type (or lack thereof). The resulting Terraform template is emitted to the terraform/bbl-template.tf file within your state directory.","title":"Generate terraform template"},{"location":"#apply-terraform-template","text":"After generating the Terraform template, bbl up will run Terraform to apply that template, using also a variables file located at vars/bbl.tfvars within the state directory.","title":"Apply terraform template"},{"location":"#map-terraform-outputs-to-bosh-create-env-vars","text":"Having applied the Terraform template, we now have a number of Terraform outputs, such as subnet CIDRs, reserved IP addresses, and load balancer configuration. bbl will transform those outputs into the inputs required by jumpbox-deployment and bosh-deployment and write them to the files vars/jumpbox-vars-file.yml and vars/director-vars-file.yml .","title":"Map terraform outputs to BOSH create-env vars"},{"location":"#execute-bosh-create-env-jumpbox-director","text":"Next, bbl shells out to the BOSH CLI to run bosh create-env twice. The first time, bbl uses jumpbox-deployment and creates the jumpbox vm; the second time, bbl uses bosh-deployment and creates the director VM. The exact commands that bbl will run are emitted to the create-jumpbox.sh and create-director.sh files within the state directory.","title":"Execute BOSH create-env (jumpbox, director)"},{"location":"#generate-cloud-config-template","text":"After the director VM comes up, bbl generates a base cloud-config, based on the IAAS, IAAS region, and chosen load balancer type.","title":"Generate cloud-config template"},{"location":"#map-terraform-outputs-to-bosh-cloud-config-vars","text":"Having generated a base cloud-config template, bbl maps Terraform outputs to cloud-config variables. These variables include network and subnetwork names, security groups or tags, and CIDR ranges, as well as load balancer target pool names.","title":"Map Terraform outputs to BOSH cloud-config vars"},{"location":"#update-cloud-config-director","text":"Finally, bbl will update the director's cloud config, by shelling out to bosh update-cloud-config .","title":"Update cloud-config (director)"},{"location":"advanced-configuration/","text":"Advanced configuration Table of Contents Using a BOSH ops-file with bbl Customizing IaaS Paving with Terraform Applying and authoring plan patches, bundled modifications to default bbl configurations. Using a BOSH ops-file with bbl About BOSH ops-files Certain features of BOSH, particularly experimental features or tuning parameters, must be enabled by modifying your Director's deployment manifest. bosh-deployment contains many such ops files for common features and options. Using the pre-made operations files You can provide any number of ops files or variables to bosh create-env by creating create-director-override.sh . This file will not be overridden by bbl. You can use create-director.sh as a template, and you can even edit that file instead, but if you do, your changes will be overridden the next time you run bbl plan . In this example, I use a local version of BOSH director that I have built based off of a branch by referencing an ops file that is included as part of bosh-deployment : bosh create-env \\ ${BBL_STATE_DIR}/bosh-deployment/bosh.yml \\ --state ${BBL_STATE_DIR}/vars/bosh-state.json \\ --vars-store ${BBL_STATE_DIR}/vars/director-vars-store.yml \\ --vars-file ${BBL_STATE_DIR}/vars/director-vars-file.yml \\ + -o ${BBL_STATE_DIR}/bosh-deployment/local-bosh-release.yml + -v local_bosh_release=${BBL_STATE_DIR}/../../build/bosh-dev.tgz -o ${BBL_STATE_DIR}/bosh-deployment/cpi.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/jumpbox-user.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/uaa.yml \\ -o ${BBL_STATE_DIR}/../shared/bosh-deployment/credhub.yml Authoring an ops-file The operations files provided by bosh-deployment may not meet your needs. In this case you will have to write your own custom ops-file. Store it somewhere outside of the bosh-deployment directory. New versions of bbl will keep the bosh-deployment directory in sync with the latest configuration and releases, so modifications may be lost when bbl plan is run in the future. Consider storing it in the top level of your state directory if it is environmentally specific, or above the state directory if it is true for all environments. Here is an example of adding an ops file that configures a few settings on all of my BOSH directors: #!/bin/sh bosh create-env \\ ${BBL_STATE_DIR}/bosh-deployment/bosh.yml \\ --state ${BBL_STATE_DIR}/vars/bosh-state.json \\ --vars-store ${BBL_STATE_DIR}/vars/director-vars-store.yml \\ --vars-file ${BBL_STATE_DIR}/vars/director-vars-file.yml \\ + -o ${BBL_STATE_DIR}/../../bbl-envs/shared/increase-workers-threads-and-flush-arp.yml -o ${BBL_STATE_DIR}/bosh-deployment/cpi.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/jumpbox-user.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/uaa.yml \\ -o ${BBL_STATE_DIR}/../shared/bosh-deployment/credhub.yml Customizing IaaS Paving with Terraform Numerous settings can be reconfigured repeatedly by editing $BBL_STATE_DIR/vars/terraform.tfvars or adding a terraform override into $BBL_STATE_DIR/terraform/my-cool-template-override.tf . Some settings, like VPCs, are not able to be changed after initial creation so it may be better to bbl plan first before running bbl up for the first time. Example: adjusting the cidr on AWS Plan the environment: mkdir some-env cd some-env export BBL_IAAS=aws export BBL_AWS_REGION=us-west-1 export BBL_AWS_ACCESS_KEY_ID=12345678 export BBL_AWS_SECRET_ACCESS_KEY=12345678 bbl plan echo -e \"\\nvpc_cidr=\\\"192.168.0.0/20\\\"\" vars/terraform.tfvars Create the environment: bbl up That's it. Your director is now at 192.168.0.6 . Plan Patches Through operations files and terraform overrides, all sorts of wild modifications can be done to the vanilla bosh environments that bbl creates. The basic principal of a plan patch is to make several modifications to a bbl plan in override files that bbl finds under terraform/ , cloud-config/ , and {create,delete}-{jumpbox,director}.sh . BBL will read and merge those into it's plan when you run bbl up . We've used plan patches to deploy bosh-lite directors on gcp , to deploy CF Isolation Segments on public clouds , and to deploy bosh managed k8s clusters with working cloud-providers using cfcr . Our plan patches are experimental. They were tested a bit when we wrote them, but we don't continuously integrate against their dependencies or even check if they still work with recent versions of terraform. They should be used with caution. Operators should make sure they understand each modification and its implications before using our patches in their own environments. Regardless, the plan-patches in this repo are great examples of the different ways you can configure bbl to deploy whatever you might need. To see all the plan patches, visit the Plan Patches README.md . If you write your own plan patch that gets you what you need, please consider upstreaming it in a PR.","title":"Advanced configuration"},{"location":"advanced-configuration/#advanced-configuration","text":"","title":"Advanced configuration"},{"location":"advanced-configuration/#table-of-contents","text":"Using a BOSH ops-file with bbl Customizing IaaS Paving with Terraform Applying and authoring plan patches, bundled modifications to default bbl configurations.","title":"Table of Contents"},{"location":"advanced-configuration/#about-bosh-ops-files","text":"Certain features of BOSH, particularly experimental features or tuning parameters, must be enabled by modifying your Director's deployment manifest. bosh-deployment contains many such ops files for common features and options.","title":"About BOSH ops-files"},{"location":"advanced-configuration/#using-the-pre-made-operations-files","text":"You can provide any number of ops files or variables to bosh create-env by creating create-director-override.sh . This file will not be overridden by bbl. You can use create-director.sh as a template, and you can even edit that file instead, but if you do, your changes will be overridden the next time you run bbl plan . In this example, I use a local version of BOSH director that I have built based off of a branch by referencing an ops file that is included as part of bosh-deployment : bosh create-env \\ ${BBL_STATE_DIR}/bosh-deployment/bosh.yml \\ --state ${BBL_STATE_DIR}/vars/bosh-state.json \\ --vars-store ${BBL_STATE_DIR}/vars/director-vars-store.yml \\ --vars-file ${BBL_STATE_DIR}/vars/director-vars-file.yml \\ + -o ${BBL_STATE_DIR}/bosh-deployment/local-bosh-release.yml + -v local_bosh_release=${BBL_STATE_DIR}/../../build/bosh-dev.tgz -o ${BBL_STATE_DIR}/bosh-deployment/cpi.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/jumpbox-user.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/uaa.yml \\ -o ${BBL_STATE_DIR}/../shared/bosh-deployment/credhub.yml","title":"Using the pre-made operations files"},{"location":"advanced-configuration/#authoring-an-ops-file","text":"The operations files provided by bosh-deployment may not meet your needs. In this case you will have to write your own custom ops-file. Store it somewhere outside of the bosh-deployment directory. New versions of bbl will keep the bosh-deployment directory in sync with the latest configuration and releases, so modifications may be lost when bbl plan is run in the future. Consider storing it in the top level of your state directory if it is environmentally specific, or above the state directory if it is true for all environments. Here is an example of adding an ops file that configures a few settings on all of my BOSH directors: #!/bin/sh bosh create-env \\ ${BBL_STATE_DIR}/bosh-deployment/bosh.yml \\ --state ${BBL_STATE_DIR}/vars/bosh-state.json \\ --vars-store ${BBL_STATE_DIR}/vars/director-vars-store.yml \\ --vars-file ${BBL_STATE_DIR}/vars/director-vars-file.yml \\ + -o ${BBL_STATE_DIR}/../../bbl-envs/shared/increase-workers-threads-and-flush-arp.yml -o ${BBL_STATE_DIR}/bosh-deployment/cpi.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/jumpbox-user.yml \\ -o ${BBL_STATE_DIR}/bosh-deployment/uaa.yml \\ -o ${BBL_STATE_DIR}/../shared/bosh-deployment/credhub.yml","title":"Authoring an ops-file"},{"location":"advanced-configuration/#example-adjusting-the-cidr-on-aws","text":"Plan the environment: mkdir some-env cd some-env export BBL_IAAS=aws export BBL_AWS_REGION=us-west-1 export BBL_AWS_ACCESS_KEY_ID=12345678 export BBL_AWS_SECRET_ACCESS_KEY=12345678 bbl plan echo -e \"\\nvpc_cidr=\\\"192.168.0.0/20\\\"\" vars/terraform.tfvars Create the environment: bbl up That's it. Your director is now at 192.168.0.6 .","title":"Example: adjusting the cidr on AWS"},{"location":"advanced-configuration/#plan-patches","text":"Through operations files and terraform overrides, all sorts of wild modifications can be done to the vanilla bosh environments that bbl creates. The basic principal of a plan patch is to make several modifications to a bbl plan in override files that bbl finds under terraform/ , cloud-config/ , and {create,delete}-{jumpbox,director}.sh . BBL will read and merge those into it's plan when you run bbl up . We've used plan patches to deploy bosh-lite directors on gcp , to deploy CF Isolation Segments on public clouds , and to deploy bosh managed k8s clusters with working cloud-providers using cfcr . Our plan patches are experimental. They were tested a bit when we wrote them, but we don't continuously integrate against their dependencies or even check if they still work with recent versions of terraform. They should be used with caution. Operators should make sure they understand each modification and its implications before using our patches in their own environments. Regardless, the plan-patches in this repo are great examples of the different ways you can configure bbl to deploy whatever you might need. To see all the plan patches, visit the Plan Patches README.md . If you write your own plan patch that gets you what you need, please consider upstreaming it in a PR.","title":" Plan Patches"},{"location":"cf-lbs/","text":"Cloud Foundry Load Balancers AWS bbl creates 3 load balancers on AWS. cf-ssh-lb In the cloud-config, this lb is referenced with the vm extension diego-ssh-proxy-network-properties . In cf-deployment, this vm extension will be associated with the scheduler vm. It forwards TCP:2222 to TCP:2222 . cf-tcp-lb In the cloud-config, this lb is referenced with the vm extension cf-tcp-router-network-properties . In cf-deployment, this vm extension will be associated with the tcp-router vm. It forwards TCP:1024-1123 to TCP:1024-1123 . cf-router-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. It forwards: HTTP:80 to HTTP:80 HTTPS:443 to HTTP:80 TLS:4443 to TCP:80 GCP bbl creates 4 load balancers on GCP. cf-router-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Compute address Backend service with an instance group per availability zone Instance group per availability zone allowing https:443 Firewall rule allowing tcp:80 tcp:443 to the backend service Health check for tcp:8080 tcp:80 cf-ws-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Compute address Target pool Forwarding rule allowing tcp:443 to the target pool Forwarding rule allowing tcp:80 to the target pool cf-tcp-router-lb In the cloud-config, this lb is referenced with the vm extension cf-tcp-router-network-properties . In cf-deployment, this vm extension will be associated with the tcp-router vm. Configuration: Compute address Target pool Firewall rule allowing tcp:1024-32768 to the target pool Forwarding rule for tcp:1024-32768 to the target pool cf-ssh-proxy-lb In the cloud-config, this lb is referenced with the vm extension diego-ssh-proxy-network-properties . In cf-deployment, this vm extension will be associated with the scheduler vm. Configuration: Compute address Target pool Firewall rule allowing tcp:2222 to the target pool Forwarding rule for tcp:2222 to the target pool Microsoft Azure bbl creates an application gateway on Microsoft Azure. cf-app-gateway In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Public IP Application Gateway Network Security Rules Network Security Group vSphere N/A. OpenStack N/A.","title":"Cloud Foundry Load Balancers"},{"location":"cf-lbs/#cloud-foundry-load-balancers","text":"","title":"Cloud Foundry Load Balancers"},{"location":"cf-lbs/#aws","text":"bbl creates 3 load balancers on AWS. cf-ssh-lb In the cloud-config, this lb is referenced with the vm extension diego-ssh-proxy-network-properties . In cf-deployment, this vm extension will be associated with the scheduler vm. It forwards TCP:2222 to TCP:2222 . cf-tcp-lb In the cloud-config, this lb is referenced with the vm extension cf-tcp-router-network-properties . In cf-deployment, this vm extension will be associated with the tcp-router vm. It forwards TCP:1024-1123 to TCP:1024-1123 . cf-router-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. It forwards: HTTP:80 to HTTP:80 HTTPS:443 to HTTP:80 TLS:4443 to TCP:80","title":"AWS"},{"location":"cf-lbs/#gcp","text":"bbl creates 4 load balancers on GCP. cf-router-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Compute address Backend service with an instance group per availability zone Instance group per availability zone allowing https:443 Firewall rule allowing tcp:80 tcp:443 to the backend service Health check for tcp:8080 tcp:80 cf-ws-lb In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Compute address Target pool Forwarding rule allowing tcp:443 to the target pool Forwarding rule allowing tcp:80 to the target pool cf-tcp-router-lb In the cloud-config, this lb is referenced with the vm extension cf-tcp-router-network-properties . In cf-deployment, this vm extension will be associated with the tcp-router vm. Configuration: Compute address Target pool Firewall rule allowing tcp:1024-32768 to the target pool Forwarding rule for tcp:1024-32768 to the target pool cf-ssh-proxy-lb In the cloud-config, this lb is referenced with the vm extension diego-ssh-proxy-network-properties . In cf-deployment, this vm extension will be associated with the scheduler vm. Configuration: Compute address Target pool Firewall rule allowing tcp:2222 to the target pool Forwarding rule for tcp:2222 to the target pool","title":"GCP"},{"location":"cf-lbs/#microsoft-azure","text":"bbl creates an application gateway on Microsoft Azure. cf-app-gateway In the cloud-config, this lb is referenced with the vm extension cf-router-network-properties . In cf-deployment, this vm extension will be associated with the router vm. Configuration: Public IP Application Gateway Network Security Rules Network Security Group","title":"Microsoft Azure"},{"location":"cf-lbs/#vsphere","text":"N/A.","title":"vSphere"},{"location":"cf-lbs/#openstack","text":"N/A.","title":"OpenStack"},{"location":"cleaning-up/","text":"Cleaning Up In addition to creating resources for deploying BOSH, bbl has two subcommands for assisting you in cleaning up an environment after you are done with it: bbl down and bbl cleanup-leftovers . bbl down If you have the state file for a working environment, then bbl will destroy everything it has created. As a safety precaution, bbl will not delete the environment if there are running VMs deployed by the BOSH director. bbl down bbl cleanup-leftovers Sometimes, bbl down isn't enough to do the job. Perhaps you are in one of these situations: bbl down failed during deletion and lost information. The bbl-state-dir is on a computer that you no longer have access to. You created resources outside of bbl that you want to nuke. You are running bbl's acceptance tests and they failed, orphaning IaaS resources. To assist with these situations, we have incorporated the cli utility leftovers as a subcommand in bbl. You can think of bbl cleanup-leftovers as kind of like bbl down --force , but without the need for a bbl-state-dir . The filter is very important! If --filter is omitted, bbl will begin to delete ALL of your IaaS account's resources. For example, if you had a bbl environment with a name autogenerated by bbl you could supply part of the name to delete it: export BBL_IAAS=aws export BBL_AWS_SECRET_ACCESS_KEY=foo export BBL_AWS_ACCESS_KEY_ID=bar bbl cleanup-leftovers --filter malawi This will begin to delete each resource with a name or tag matching \"malawi\", confirming each one before deletion. Use caution with your filters, because you may have more than one environment with the same \"Lake Name\". To delete all resources with that name without needing to confirming each one individually use --no-confim : bbl cleanup-leftovers --filter malawi --no-confirm bbl cleanup-leftovers will do the best it can to delete in an order such that all resources can be deleted without dependency errors. However, running cleanup-leftovers repeatedly may be enough to resolve dependency errors.","title":"Cleaning Up"},{"location":"cleaning-up/#cleaning-up","text":"In addition to creating resources for deploying BOSH, bbl has two subcommands for assisting you in cleaning up an environment after you are done with it: bbl down and bbl cleanup-leftovers .","title":"Cleaning Up"},{"location":"cleaning-up/#bbl-down","text":"If you have the state file for a working environment, then bbl will destroy everything it has created. As a safety precaution, bbl will not delete the environment if there are running VMs deployed by the BOSH director. bbl down","title":"bbl down"},{"location":"cleaning-up/#bbl-cleanup-leftovers","text":"Sometimes, bbl down isn't enough to do the job. Perhaps you are in one of these situations: bbl down failed during deletion and lost information. The bbl-state-dir is on a computer that you no longer have access to. You created resources outside of bbl that you want to nuke. You are running bbl's acceptance tests and they failed, orphaning IaaS resources. To assist with these situations, we have incorporated the cli utility leftovers as a subcommand in bbl. You can think of bbl cleanup-leftovers as kind of like bbl down --force , but without the need for a bbl-state-dir . The filter is very important! If --filter is omitted, bbl will begin to delete ALL of your IaaS account's resources. For example, if you had a bbl environment with a name autogenerated by bbl you could supply part of the name to delete it: export BBL_IAAS=aws export BBL_AWS_SECRET_ACCESS_KEY=foo export BBL_AWS_ACCESS_KEY_ID=bar bbl cleanup-leftovers --filter malawi This will begin to delete each resource with a name or tag matching \"malawi\", confirming each one before deletion. Use caution with your filters, because you may have more than one environment with the same \"Lake Name\". To delete all resources with that name without needing to confirming each one individually use --no-confim : bbl cleanup-leftovers --filter malawi --no-confirm bbl cleanup-leftovers will do the best it can to delete in an order such that all resources can be deleted without dependency errors. However, running cleanup-leftovers repeatedly may be enough to resolve dependency errors.","title":"bbl cleanup-leftovers"},{"location":"cloudfoundry/","text":"Generic Steps for Cloud Foundry Deployment Create an environment and target the BOSH director with eval \"$(bbl print-env)\" bbl plan --lb-type cf --lb-cert PATH_TO_CERT_FILE --lb-key PATH_TO_KEY_FILE bbl up . You can use existing certificate and key files, or generate new ones. See below for instructions on generating these files for Microsoft Azure. bosh deploy cf-deployment.yml -o operations/ MY IaaS using the CF deployment manifest! Appendix: Generating Load Balancer Key and Certificate Files for Microsoft Azure To create Cloud Foundry load balancers for Microsoft Azure you must provide a certificate in the .pfx format: openssl genrsa -out DOMAIN_NAME.key 2048 openssl req -new -x509 -days 365 -key DOMAIN_NAME.key -out DOMAIN_NAME.crt openssl pkcs12 -export -out PFX_FILE -inkey DOMAIN_NAME.key -in DOMAIN_NAME.crt Save the password you entered when prompted by openssl to a file. echo SuperSecretPassword PFX_FILE_PASSWORD To bbl plan or bbl up you can provide the .pfx file and password: bbl plan --lb-type cf --lb-cert PFX_FILE --lb-key PFX_FILE_PASSWORD","title":"Generic Steps for Cloud Foundry Deployment"},{"location":"cloudfoundry/#generic-steps-for-cloud-foundry-deployment","text":"Create an environment and target the BOSH director with eval \"$(bbl print-env)\" bbl plan --lb-type cf --lb-cert PATH_TO_CERT_FILE --lb-key PATH_TO_KEY_FILE bbl up . You can use existing certificate and key files, or generate new ones. See below for instructions on generating these files for Microsoft Azure. bosh deploy cf-deployment.yml -o operations/ MY IaaS using the CF deployment manifest!","title":"Generic Steps for Cloud Foundry Deployment"},{"location":"cloudfoundry/#appendix-generating-load-balancer-key-and-certificate-files-for-microsoft-azure","text":"To create Cloud Foundry load balancers for Microsoft Azure you must provide a certificate in the .pfx format: openssl genrsa -out DOMAIN_NAME.key 2048 openssl req -new -x509 -days 365 -key DOMAIN_NAME.key -out DOMAIN_NAME.crt openssl pkcs12 -export -out PFX_FILE -inkey DOMAIN_NAME.key -in DOMAIN_NAME.crt Save the password you entered when prompted by openssl to a file. echo SuperSecretPassword PFX_FILE_PASSWORD To bbl plan or bbl up you can provide the .pfx file and password: bbl plan --lb-type cf --lb-cert PFX_FILE --lb-key PFX_FILE_PASSWORD","title":"Appendix: Generating Load Balancer Key and Certificate Files for Microsoft Azure"},{"location":"concourse/","text":"Concourse Prerequisites If one has followed the BBL steps mentioned in the IaaS-Specific Getting Started Guides , the foundation has been created according to your IaaS of choice, which typically includes: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config Deploy Concourse Cluster On top of these, below are the typical steps to deploy Concourse cluster. 1. Create Concourse LB Let's run our scripts in the folder where one ran the bbl up . bbl plan --lb-type concourse bbl up Note: this will create a new IaaS Load Balancer, with some ports (80, 443, 2222, 8443, 8844) pre-configured and opened, to front Concourse web node(s). 2. Prepare for Concourse Deployment eval $(bbl print-env) export IAAS= $(cat bbl-state.json | jq -r .iaas) if [ ${IAAS} = aws ]; then export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_url | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-aws-xen-hvm-ubuntu-xenial-go_agent elif [ ${IAAS} = gcp ]; then export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_ip | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-google-kvm-ubuntu-xenial-go_agent else # Azure export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_ip | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-azure-hyperv-ubuntu-xenial-go_agent fi bosh upload-stemcell ${STEMCELL_URL} 3. Customize Deploy git clone https://github.com/concourse/concourse-bosh-deployment.git pushd concourse-bosh-deployment/cluster export USERNAME= username export PASSWORD= super-secure-password cat ../../vars/concourse-vars-file.yml EOL external_host: ${EXTERNAL_HOST} external_url: https://${EXTERNAL_HOST} local_user: username: ${USERNAME} password: ${PASSWORD} network_name: 'private' web_instances: 1 web_network_name: 'private' web_vm_type: 'default' web_network_vm_extension: 'lb' db_vm_type: 'default' db_persistent_disk_type: '1GB' worker_instances: 2 worker_vm_type: 'default' worker_ephemeral_disk: '50GB_ephemeral_disk' deployment_name: 'concourse' EOL bosh deploy -d concourse concourse.yml \\ -l ../versions.yml \\ -l ../../vars/concourse-vars-file.yml \\ -o operations/basic-auth.yml \\ -o operations/privileged-http.yml \\ -o operations/privileged-https.yml \\ -o operations/tls.yml \\ -o operations/tls-vars.yml \\ -o operations/web-network-extension.yml \\ -o operations/scale.yml \\ -o operations/worker-ephemeral-disk.yml popd Note: do check it out here for tons of operations files by which one can tune / customize the Concourse cluster. 4. Check It Out Once it's successfully done, we can simply check it out. View the BOSH VMs' status: bosh -d concourse vms ... Deployment 'concourse' Instance Process State AZ IPs VM CID VM Type Active db/e3921a7d-ca25-4abc-9860-8fae73625507 running z1 10.0.1.1 vm-ebe33d11-a858-45bf-61eb-89eff5bb86f8 default true web/dffa0d32-6e2d-446e-838f-ecfff86f0d51 running z1 10.0.1.0 vm-6d4585b5-fda2-4215-547a-b249de8b1384 default true worker/06c58730-35f1-4c2f-9bb0-10f0216f8491 running z1 10.0.1.2 vm-026513ed-85c7-47aa-7260-0fe7c286af36 default true worker/3a0945f5-b59d-4ef9-8002-d7c8468c2f59 running z1 10.0.1.3 vm-4ee75638-ba98-4474-7719-b523b3fabd23 default true 4 vms Succeeded Open Concourse in Browser: open `bosh int vars/concourse-vars-file.yml --path /external_url` And login with username/password from below output: bosh int vars/concourse-vars-file.yml --path /local_user","title":"Concourse"},{"location":"concourse/#concourse","text":"","title":"Concourse"},{"location":"concourse/#prerequisites","text":"If one has followed the BBL steps mentioned in the IaaS-Specific Getting Started Guides , the foundation has been created according to your IaaS of choice, which typically includes: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config","title":"Prerequisites"},{"location":"concourse/#deploy-concourse-cluster","text":"On top of these, below are the typical steps to deploy Concourse cluster.","title":"Deploy Concourse Cluster"},{"location":"concourse/#1-create-concourse-lb","text":"Let's run our scripts in the folder where one ran the bbl up . bbl plan --lb-type concourse bbl up Note: this will create a new IaaS Load Balancer, with some ports (80, 443, 2222, 8443, 8844) pre-configured and opened, to front Concourse web node(s).","title":"1. Create Concourse LB"},{"location":"concourse/#2-prepare-for-concourse-deployment","text":"eval $(bbl print-env) export IAAS= $(cat bbl-state.json | jq -r .iaas) if [ ${IAAS} = aws ]; then export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_url | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-aws-xen-hvm-ubuntu-xenial-go_agent elif [ ${IAAS} = gcp ]; then export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_ip | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-google-kvm-ubuntu-xenial-go_agent else # Azure export EXTERNAL_HOST= $(bbl outputs | grep concourse_lb_ip | cut -d ' ' -f2) export STEMCELL_URL= https://bosh.io/d/stemcells/bosh-azure-hyperv-ubuntu-xenial-go_agent fi bosh upload-stemcell ${STEMCELL_URL}","title":"2. Prepare for Concourse Deployment"},{"location":"concourse/#3-customize-deploy","text":"git clone https://github.com/concourse/concourse-bosh-deployment.git pushd concourse-bosh-deployment/cluster export USERNAME= username export PASSWORD= super-secure-password cat ../../vars/concourse-vars-file.yml EOL external_host: ${EXTERNAL_HOST} external_url: https://${EXTERNAL_HOST} local_user: username: ${USERNAME} password: ${PASSWORD} network_name: 'private' web_instances: 1 web_network_name: 'private' web_vm_type: 'default' web_network_vm_extension: 'lb' db_vm_type: 'default' db_persistent_disk_type: '1GB' worker_instances: 2 worker_vm_type: 'default' worker_ephemeral_disk: '50GB_ephemeral_disk' deployment_name: 'concourse' EOL bosh deploy -d concourse concourse.yml \\ -l ../versions.yml \\ -l ../../vars/concourse-vars-file.yml \\ -o operations/basic-auth.yml \\ -o operations/privileged-http.yml \\ -o operations/privileged-https.yml \\ -o operations/tls.yml \\ -o operations/tls-vars.yml \\ -o operations/web-network-extension.yml \\ -o operations/scale.yml \\ -o operations/worker-ephemeral-disk.yml popd Note: do check it out here for tons of operations files by which one can tune / customize the Concourse cluster.","title":"3. Customize &amp; Deploy"},{"location":"concourse/#4-check-it-out","text":"Once it's successfully done, we can simply check it out. View the BOSH VMs' status: bosh -d concourse vms ... Deployment 'concourse' Instance Process State AZ IPs VM CID VM Type Active db/e3921a7d-ca25-4abc-9860-8fae73625507 running z1 10.0.1.1 vm-ebe33d11-a858-45bf-61eb-89eff5bb86f8 default true web/dffa0d32-6e2d-446e-838f-ecfff86f0d51 running z1 10.0.1.0 vm-6d4585b5-fda2-4215-547a-b249de8b1384 default true worker/06c58730-35f1-4c2f-9bb0-10f0216f8491 running z1 10.0.1.2 vm-026513ed-85c7-47aa-7260-0fe7c286af36 default true worker/3a0945f5-b59d-4ef9-8002-d7c8468c2f59 running z1 10.0.1.3 vm-4ee75638-ba98-4474-7719-b523b3fabd23 default true 4 vms Succeeded Open Concourse in Browser: open `bosh int vars/concourse-vars-file.yml --path /external_url` And login with username/password from below output: bosh int vars/concourse-vars-file.yml --path /local_user","title":"4. Check It Out"},{"location":"credhub/","text":"Accessing the BOSH Director CredHub Using CREDHUB_PROXY Requirements bbl v6.2 or above credhub-cli v1.6.0 or above a bbl environment Instructions Set necessary environment variables bbl print-env prints out environment variables ( CREDHUB_CLIENT , CREDHUB_SECRET , CREDHUB_PROXY , CREDHUB_SERVER , CREDHUB_CA_CERT , and others) that need to be exported to target the Director CredHub using the CredHub CLI. eval \"$(bbl print-env)\" Get credentials credhub find -n 'cf_admin_password' The CredHub CLI will parse CREDHUB_PROXY and determines from the ssh+socks5:// scheme that it should proxy throuhg a jumpbox via a tunnel of its own making. Using http_proxy Requirements bbl credhub-cli a bbl environment Instructions Set your CredHub client/secret eval \"$(bbl print-env)\" Make an SSH tunnel to the jumpbox bbl ssh-key /tmp/jumpbox.key chmod 0700 /tmp/jumpbox.key ssh -4 -D 5000 -fNC jumpbox@`bbl jumpbox-address` -i /tmp/jumpbox.key Login http_proxy=socks5://localhost:5000 credhub login Get credentials http_proxy=socks5://localhost:5000 credhub find -n 'cf_admin_password'","title":"Accessing the BOSH Director CredHub"},{"location":"credhub/#accessing-the-bosh-director-credhub","text":"","title":"Accessing the BOSH Director CredHub"},{"location":"credhub/#using-credhub_proxy","text":"","title":"Using CREDHUB_PROXY"},{"location":"credhub/#requirements","text":"bbl v6.2 or above credhub-cli v1.6.0 or above a bbl environment","title":"Requirements"},{"location":"credhub/#instructions","text":"Set necessary environment variables bbl print-env prints out environment variables ( CREDHUB_CLIENT , CREDHUB_SECRET , CREDHUB_PROXY , CREDHUB_SERVER , CREDHUB_CA_CERT , and others) that need to be exported to target the Director CredHub using the CredHub CLI. eval \"$(bbl print-env)\" Get credentials credhub find -n 'cf_admin_password' The CredHub CLI will parse CREDHUB_PROXY and determines from the ssh+socks5:// scheme that it should proxy throuhg a jumpbox via a tunnel of its own making.","title":"Instructions"},{"location":"credhub/#using-http_proxy","text":"","title":"Using http_proxy"},{"location":"credhub/#requirements_1","text":"bbl credhub-cli a bbl environment","title":"Requirements"},{"location":"credhub/#instructions_1","text":"Set your CredHub client/secret eval \"$(bbl print-env)\" Make an SSH tunnel to the jumpbox bbl ssh-key /tmp/jumpbox.key chmod 0700 /tmp/jumpbox.key ssh -4 -D 5000 -fNC jumpbox@`bbl jumpbox-address` -i /tmp/jumpbox.key Login http_proxy=socks5://localhost:5000 credhub login Get credentials http_proxy=socks5://localhost:5000 credhub find -n 'cf_admin_password'","title":"Instructions"},{"location":"customization/","text":"Customizing your infrastructure and director Since version 5.2.0, bbl has allowed customizing the infrastructure and director by editing files within the bbl state dir. This is a guide to which files can and can't be customized. Files and directories that cannot be overridden or customized There are 3 directories and one file in the bbl state directory which should not be modified by the user. bbl-ops-files The bbl-ops-files directory contains ops files for bosh-deployment and jumpbox-deployment which are used by bbl but not part of the main bosh-deployment or jumpbox-deployment repositories. bbl-state.json The bbl-state.json file is used to keep track of several different aspects of state that aren't captured by the rest of the state dir: - load balancer type, cert, and key - most recent output from Terraform (useful when running without --debug ; this will be printed when running bbl latest-error ) - BOSH director information, including: - username and password - address - SSL certificate, private key, and CA - jumpbox URL - environment name - IAAS - bbl version used to create the state bosh-deployment This is a copy of the cloudfoundry/bosh-deployment Git repository. It contains the base BOSH director manifest, as well as ops files that configure the CPI, add UAA and Credhub to the director, and allow SSH access to the director. The entire repository is provided, not just the files that bbl uses in its default director create-env script. jumpbox-deployment This is a copy of the cloudfoundry/jumpbox-deployment Git repository. It contains the base jumpbox manifest, as well as ops files that configure the CPI. As with the bosh-deployment directory, the entire Git repository is provided, not just the files bbl uses. Override scripts To create and destroy the jumpbox and director deployments, bbl does not shell out directly to the BOSH CLI. Instead, it uses four wrapper scripts, which are emitted into the root of the state directory as create-jumpbox.sh , create-director.sh , delete-jumpbox.sh , and delete-director.sh . These files will be rewritten when running bbl plan , so editing them directly is not recommended. However, if a file with the name create-jumpbox-override.sh is present in the root of the state directory, bbl will run that script instead of create-jumpbox.sh when creating a jumpbox. The same goes for the other counterparts: create-director-override.sh , delete- jumpbox-override.sh , and delete-director-override.sh . Directories where the user can add files cloud-config Any ops file with a name of the form *.yml that is added to the cloud-config directory will be used as an ops file argument by bbl when it runs update-cloud-config . The ops files will be applied in alphabetical order. Modifying the cloud-config.yml and ops.yml files directly is not recommended if you can avoid it, as these files will be rewritten on bbl plan , while other files in the directory will be preserved even if you re-run bbl plan . terraform Adding an HCL file with a *.tf filename to the terraform directory will effectively append that file to the bbl terraform template. Adding an HCL file with a *_override.tf filename will merge that file with the bbl terraform template when bbl runs terraform apply or terraform destroy . If you are modifying any bbl - provided Terraform resources using a custom Terraform file, we recommend that you end your filename in _override.tf in order for Terraform to properly process those modifications. Changes to the bbl.tf file will be lost on re-running bbl plan , but all other files in the directory will not be modified. vars Adding a file with a *.tfvars filename to the vars directory will allow custom variables to be picked up by Terraform when bbl runs terraform apply . The general format of a tfvars file is key=\"value\" . Values longer than one line can be provided using heredoc syntax, for instance: aws_iam_access_policy = EOF { Version : 2012-10-17 , Statement : [ { ... } ] } EOF Modifying the bbl.tfvars file directly can change the variables used in the base Terraform template; however, this is not recommended since these variables are generated by bbl from credentials and other user-provided settings and may be overwritten by subsequent bbl runs. Instead, you should alter the input to bbl plan . bbl provides several files within the vars directory, and will edit them on subsequent runs. These files include: - bbl.tfvars - used by bbl to provide credentials and other user-provided settings to Terraform - bosh-state.json - used by the BOSH CLI to store state for the BOSH director deployment - cloud-config-vars.yml - used by bbl to provide Terraform outputs to the BOSH cloud-config - director-vars-file.yml - used by bbl to provide Terraform outputs to the BOSH create-env call for the director - director-vars-store.yml - used by the BOSH CLI to store generated variables for the BOSH director deployment - jumpbox-state.json - used by the BOSH CLI to store state for the jumpbox deployment - jumpbox-vars-file.yml - used by bbl to provide Terraform outputs to the BOSH create-env call for the jumpbox - jumpbox-vars-store.yml - used by the BOSH CLI to store generated variables for the BOSH jumpbox deployment - terraform.tfstate and terraform.tfstate.backup - used by the Terraform CLI to store state These files should not be edited by the user. All other files placed in the vars directory are safe and will not be modified by bbl .","title":"Customizing your infrastructure and director"},{"location":"customization/#customizing-your-infrastructure-and-director","text":"Since version 5.2.0, bbl has allowed customizing the infrastructure and director by editing files within the bbl state dir. This is a guide to which files can and can't be customized.","title":"Customizing your infrastructure and director"},{"location":"customization/#files-and-directories-that-cannot-be-overridden-or-customized","text":"There are 3 directories and one file in the bbl state directory which should not be modified by the user.","title":"Files and directories that cannot be overridden or customized"},{"location":"customization/#bbl-ops-files","text":"The bbl-ops-files directory contains ops files for bosh-deployment and jumpbox-deployment which are used by bbl but not part of the main bosh-deployment or jumpbox-deployment repositories.","title":"bbl-ops-files"},{"location":"customization/#bbl-statejson","text":"The bbl-state.json file is used to keep track of several different aspects of state that aren't captured by the rest of the state dir: - load balancer type, cert, and key - most recent output from Terraform (useful when running without --debug ; this will be printed when running bbl latest-error ) - BOSH director information, including: - username and password - address - SSL certificate, private key, and CA - jumpbox URL - environment name - IAAS - bbl version used to create the state","title":"bbl-state.json"},{"location":"customization/#bosh-deployment","text":"This is a copy of the cloudfoundry/bosh-deployment Git repository. It contains the base BOSH director manifest, as well as ops files that configure the CPI, add UAA and Credhub to the director, and allow SSH access to the director. The entire repository is provided, not just the files that bbl uses in its default director create-env script.","title":"bosh-deployment"},{"location":"customization/#jumpbox-deployment","text":"This is a copy of the cloudfoundry/jumpbox-deployment Git repository. It contains the base jumpbox manifest, as well as ops files that configure the CPI. As with the bosh-deployment directory, the entire Git repository is provided, not just the files bbl uses.","title":"jumpbox-deployment"},{"location":"customization/#override-scripts","text":"To create and destroy the jumpbox and director deployments, bbl does not shell out directly to the BOSH CLI. Instead, it uses four wrapper scripts, which are emitted into the root of the state directory as create-jumpbox.sh , create-director.sh , delete-jumpbox.sh , and delete-director.sh . These files will be rewritten when running bbl plan , so editing them directly is not recommended. However, if a file with the name create-jumpbox-override.sh is present in the root of the state directory, bbl will run that script instead of create-jumpbox.sh when creating a jumpbox. The same goes for the other counterparts: create-director-override.sh , delete- jumpbox-override.sh , and delete-director-override.sh .","title":"Override scripts"},{"location":"customization/#directories-where-the-user-can-add-files","text":"","title":"Directories where the user can add files"},{"location":"customization/#cloud-config","text":"Any ops file with a name of the form *.yml that is added to the cloud-config directory will be used as an ops file argument by bbl when it runs update-cloud-config . The ops files will be applied in alphabetical order. Modifying the cloud-config.yml and ops.yml files directly is not recommended if you can avoid it, as these files will be rewritten on bbl plan , while other files in the directory will be preserved even if you re-run bbl plan .","title":"cloud-config"},{"location":"customization/#terraform","text":"Adding an HCL file with a *.tf filename to the terraform directory will effectively append that file to the bbl terraform template. Adding an HCL file with a *_override.tf filename will merge that file with the bbl terraform template when bbl runs terraform apply or terraform destroy . If you are modifying any bbl - provided Terraform resources using a custom Terraform file, we recommend that you end your filename in _override.tf in order for Terraform to properly process those modifications. Changes to the bbl.tf file will be lost on re-running bbl plan , but all other files in the directory will not be modified.","title":"terraform"},{"location":"customization/#vars","text":"Adding a file with a *.tfvars filename to the vars directory will allow custom variables to be picked up by Terraform when bbl runs terraform apply . The general format of a tfvars file is key=\"value\" . Values longer than one line can be provided using heredoc syntax, for instance: aws_iam_access_policy = EOF { Version : 2012-10-17 , Statement : [ { ... } ] } EOF Modifying the bbl.tfvars file directly can change the variables used in the base Terraform template; however, this is not recommended since these variables are generated by bbl from credentials and other user-provided settings and may be overwritten by subsequent bbl runs. Instead, you should alter the input to bbl plan . bbl provides several files within the vars directory, and will edit them on subsequent runs. These files include: - bbl.tfvars - used by bbl to provide credentials and other user-provided settings to Terraform - bosh-state.json - used by the BOSH CLI to store state for the BOSH director deployment - cloud-config-vars.yml - used by bbl to provide Terraform outputs to the BOSH cloud-config - director-vars-file.yml - used by bbl to provide Terraform outputs to the BOSH create-env call for the director - director-vars-store.yml - used by the BOSH CLI to store generated variables for the BOSH director deployment - jumpbox-state.json - used by the BOSH CLI to store state for the jumpbox deployment - jumpbox-vars-file.yml - used by bbl to provide Terraform outputs to the BOSH create-env call for the jumpbox - jumpbox-vars-store.yml - used by the BOSH CLI to store generated variables for the BOSH jumpbox deployment - terraform.tfstate and terraform.tfstate.backup - used by the Terraform CLI to store state These files should not be edited by the user. All other files placed in the vars directory are safe and will not be modified by bbl .","title":"vars"},{"location":"getting-started-aws/","text":"Getting Started: AWS This guide is a walkthrough for deploying a BOSH director with bbl on AWS. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config Creating an IAM user In order for bbl to interact with AWS, an IAM user must be created. This user will be issuing API requests to create the infrastructure such as EC2 instances, load balancers, subnets, etc. The user must have the following policy : { Version : 2012-10-17 , Statement : [ { Sid : VisualEditor0 , Effect : Allow , Action : [ logs:* , elasticloadbalancing:* , cloudformation:* , iam:* , kms:* , route53:* , ec2:* ], Resource : * } ] } To create a user and associated policy with the AWS CLI run the following commands (policy text must be in your clipboard): $ aws iam create-user --user-name bbl-user $ aws iam put-user-policy --user-name bbl-user \\ --policy-name bbl-policy \\ --policy-document $(pbpaste) $ aws iam create-access-key --user-name bbl-user The create-access-key command will write an \"access key id\" and \"secret access key\" to the terminal. These values are important and should be kept secret. In the next section bbl will use these commands to create infrastructure on AWS. Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director bbl will create infrastructure and deploy a BOSH director with the following command: bbl up \\ --aws-access-key-id INSERT ACCESS KEY ID \\ --aws-secret-access-key INSERT SECRET ACCESS KEY \\ --aws-region us-west-1 \\ --iaas aws The process takes around 5-8 minutes. The bbl state directory contains all of the files that were used to create your bosh director. This should be checked in to version control, so that you have all the information necessary to later destroy or update this environment at a later date. Next Steps Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Getting Started: AWS"},{"location":"getting-started-aws/#getting-started-aws","text":"This guide is a walkthrough for deploying a BOSH director with bbl on AWS. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config","title":"Getting Started: AWS"},{"location":"getting-started-aws/#creating-an-iam-user","text":"In order for bbl to interact with AWS, an IAM user must be created. This user will be issuing API requests to create the infrastructure such as EC2 instances, load balancers, subnets, etc. The user must have the following policy : { Version : 2012-10-17 , Statement : [ { Sid : VisualEditor0 , Effect : Allow , Action : [ logs:* , elasticloadbalancing:* , cloudformation:* , iam:* , kms:* , route53:* , ec2:* ], Resource : * } ] } To create a user and associated policy with the AWS CLI run the following commands (policy text must be in your clipboard): $ aws iam create-user --user-name bbl-user $ aws iam put-user-policy --user-name bbl-user \\ --policy-name bbl-policy \\ --policy-document $(pbpaste) $ aws iam create-access-key --user-name bbl-user The create-access-key command will write an \"access key id\" and \"secret access key\" to the terminal. These values are important and should be kept secret. In the next section bbl will use these commands to create infrastructure on AWS.","title":"Creating an IAM user"},{"location":"getting-started-aws/#pave-infrastructure-create-a-jumpbox-and-create-a-bosh-director","text":"bbl will create infrastructure and deploy a BOSH director with the following command: bbl up \\ --aws-access-key-id INSERT ACCESS KEY ID \\ --aws-secret-access-key INSERT SECRET ACCESS KEY \\ --aws-region us-west-1 \\ --iaas aws The process takes around 5-8 minutes. The bbl state directory contains all of the files that were used to create your bosh director. This should be checked in to version control, so that you have all the information necessary to later destroy or update this environment at a later date.","title":"Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director"},{"location":"getting-started-aws/#next-steps","text":"Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Next Steps"},{"location":"getting-started-azure/","text":"Getting Started: Microsoft Azure This guide is a walkthrough for deploying a BOSH director with bbl on Microsoft Azure. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config Create a Service Principal Account You can use the cli utility az-automation for creating a service principal account given you have authenticated with the az cli. The output will include your subscription id, your tenant id, the client id, and the client secret. These credentials will be passed to bbl so that it can interact with Azure. Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director Export environment variables. export BBL_IAAS=azure export BBL_AZURE_CLIENT_ID= export BBL_AZURE_CLIENT_SECRET= export BBL_AZURE_REGION= export BBL_AZURE_SUBSCRIPTION_ID= export BBL_AZURE_TENANT_ID= or powershell: powershell $env:BBL_IAAS=\"azure\" $env:BBL_AZURE_CLIENT_ID= $env:BBL_AZURE_CLIENT_SECRET= $env:BBL_AZURE_REGION= $env:BBL_AZURE_SUBSCRIPTION_ID= $env:BBL_AZURE_TENANT_ID= Create infrastructure, jumpbox, and bosh director. bbl up Next Steps Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Getting Started: Microsoft Azure"},{"location":"getting-started-azure/#getting-started-microsoft-azure","text":"This guide is a walkthrough for deploying a BOSH director with bbl on Microsoft Azure. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config","title":"Getting Started: Microsoft Azure"},{"location":"getting-started-azure/#create-a-service-principal-account","text":"You can use the cli utility az-automation for creating a service principal account given you have authenticated with the az cli. The output will include your subscription id, your tenant id, the client id, and the client secret. These credentials will be passed to bbl so that it can interact with Azure.","title":"Create a Service Principal Account"},{"location":"getting-started-azure/#pave-infrastructure-create-a-jumpbox-and-create-a-bosh-director","text":"Export environment variables. export BBL_IAAS=azure export BBL_AZURE_CLIENT_ID= export BBL_AZURE_CLIENT_SECRET= export BBL_AZURE_REGION= export BBL_AZURE_SUBSCRIPTION_ID= export BBL_AZURE_TENANT_ID= or powershell: powershell $env:BBL_IAAS=\"azure\" $env:BBL_AZURE_CLIENT_ID= $env:BBL_AZURE_CLIENT_SECRET= $env:BBL_AZURE_REGION= $env:BBL_AZURE_SUBSCRIPTION_ID= $env:BBL_AZURE_TENANT_ID= Create infrastructure, jumpbox, and bosh director. bbl up","title":"Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director"},{"location":"getting-started-azure/#next-steps","text":"Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Next Steps"},{"location":"getting-started-gcp/","text":"Getting Started: GCP This guide is a walkthrough for deploying a BOSH director with bbl on GCP. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config Create a Service Account In order for bbl to interact with GCP, a service account must be created. gcloud iam service-accounts create service account name gcloud iam service-accounts keys create --iam-account=' service account name @ project id .iam.gserviceaccount.com' service account name .key.json gcloud projects add-iam-policy-binding project id --member='serviceAccount: service account name @ project id .iam.gserviceaccount.com' --role='roles/editor' Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director Export environment variables. export BBL_IAAS=gcp export BBL_GCP_REGION= export BBL_GCP_SERVICE_ACCOUNT_KEY= or powershell: powershell $env:BBL_IAAS=\"gcp\" $env:BBL_GCP_REGION= $env:BBL_GCP_SERVICE_ACCOUNT_KEY= 1. Create an empty directory to use as your bbl state directory. mkdir some-bbl-state-dir cd some-bbl-state-dir 1. Create infrastructure, jumpbox, and bosh director. bbl up Next Steps Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Getting Started: GCP"},{"location":"getting-started-gcp/#getting-started-gcp","text":"This guide is a walkthrough for deploying a BOSH director with bbl on GCP. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config","title":"Getting Started: GCP"},{"location":"getting-started-gcp/#create-a-service-account","text":"In order for bbl to interact with GCP, a service account must be created. gcloud iam service-accounts create service account name gcloud iam service-accounts keys create --iam-account=' service account name @ project id .iam.gserviceaccount.com' service account name .key.json gcloud projects add-iam-policy-binding project id --member='serviceAccount: service account name @ project id .iam.gserviceaccount.com' --role='roles/editor'","title":"Create a Service Account"},{"location":"getting-started-gcp/#pave-infrastructure-create-a-jumpbox-and-create-a-bosh-director","text":"Export environment variables. export BBL_IAAS=gcp export BBL_GCP_REGION= export BBL_GCP_SERVICE_ACCOUNT_KEY= or powershell: powershell $env:BBL_IAAS=\"gcp\" $env:BBL_GCP_REGION= $env:BBL_GCP_SERVICE_ACCOUNT_KEY= 1. Create an empty directory to use as your bbl state directory. mkdir some-bbl-state-dir cd some-bbl-state-dir 1. Create infrastructure, jumpbox, and bosh director. bbl up","title":"Pave Infrastructure, Create a Jumpbox, and Create a BOSH Director"},{"location":"getting-started-gcp/#next-steps","text":"Target the BOSH Director Deploy Cloud Foundry Deploy Concourse","title":"Next Steps"},{"location":"getting-started-openstack/","text":"Getting Started: OpenStack This guide is a walkthrough for deploying a BOSH director with bbl on OpenStack. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config bbl creates and maintains the lifecycle of the jumpbox and BOSH director. It does not create any networks, security groups, or load balancers on OpenStack. Create a Jumpbox and a BOSH Director Export environment variables. export BBL_IAAS=openstack export BBL_OPENSTACK_INTERNAL_CIDR= export BBL_OPENSTACK_EXTERNAL_IP= export BBL_OPENSTACK_AUTH_URL= export BBL_OPENSTACK_AZ= export BBL_OPENSTACK_DEFAULT_KEY_NAME= export BBL_OPENSTACK_DEFAULT_SECURITY_GROUP= export BBL_OPENSTACK_NETWORK_ID= export BBL_OPENSTACK_PASSWORD= export BBL_OPENSTACK_USERNAME= export BBL_OPENSTACK_PROJECT= export BBL_OPENSTACK_DOMAIN= export BBL_OPENSTACK_REGION= export BBL_OPENSTACK_PRIVATE_KEY= powershell $env:BBL_IAAS=\"openstack\" $env:BBL_OPENSTACK_INTERNAL_CIDR= $env:BBL_OPENSTACK_EXTERNAL_IP= $env:BBL_OPENSTACK_AUTH_URL= $env:BBL_OPENSTACK_AZ= $env:BBL_OPENSTACK_DEFAULT_KEY_NAME= $env:BBL_OPENSTACK_DEFAULT_SECURITY_GROUP= $env:BBL_OPENSTACK_NETWORK_ID= $env:BBL_OPENSTACK_PASSWORD= $env:BBL_OPENSTACK_USERNAME= $env:BBL_OPENSTACK_PROJECT= $env:BBL_OPENSTACK_DOMAIN= $env:BBL_OPENSTACK_REGION= $env:BBL_OPENSTACK_PRIVATE_KEY= 1. Create jumpbox and bosh director. bbl up Next Steps Target the BOSH Director","title":"Getting Started: OpenStack"},{"location":"getting-started-openstack/#getting-started-openstack","text":"This guide is a walkthrough for deploying a BOSH director with bbl on OpenStack. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config bbl creates and maintains the lifecycle of the jumpbox and BOSH director. It does not create any networks, security groups, or load balancers on OpenStack.","title":"Getting Started: OpenStack"},{"location":"getting-started-openstack/#create-a-jumpbox-and-a-bosh-director","text":"Export environment variables. export BBL_IAAS=openstack export BBL_OPENSTACK_INTERNAL_CIDR= export BBL_OPENSTACK_EXTERNAL_IP= export BBL_OPENSTACK_AUTH_URL= export BBL_OPENSTACK_AZ= export BBL_OPENSTACK_DEFAULT_KEY_NAME= export BBL_OPENSTACK_DEFAULT_SECURITY_GROUP= export BBL_OPENSTACK_NETWORK_ID= export BBL_OPENSTACK_PASSWORD= export BBL_OPENSTACK_USERNAME= export BBL_OPENSTACK_PROJECT= export BBL_OPENSTACK_DOMAIN= export BBL_OPENSTACK_REGION= export BBL_OPENSTACK_PRIVATE_KEY= powershell $env:BBL_IAAS=\"openstack\" $env:BBL_OPENSTACK_INTERNAL_CIDR= $env:BBL_OPENSTACK_EXTERNAL_IP= $env:BBL_OPENSTACK_AUTH_URL= $env:BBL_OPENSTACK_AZ= $env:BBL_OPENSTACK_DEFAULT_KEY_NAME= $env:BBL_OPENSTACK_DEFAULT_SECURITY_GROUP= $env:BBL_OPENSTACK_NETWORK_ID= $env:BBL_OPENSTACK_PASSWORD= $env:BBL_OPENSTACK_USERNAME= $env:BBL_OPENSTACK_PROJECT= $env:BBL_OPENSTACK_DOMAIN= $env:BBL_OPENSTACK_REGION= $env:BBL_OPENSTACK_PRIVATE_KEY= 1. Create jumpbox and bosh director. bbl up","title":"Create a Jumpbox and a BOSH Director"},{"location":"getting-started-openstack/#next-steps","text":"Target the BOSH Director","title":"Next Steps"},{"location":"getting-started-vsphere/","text":"Getting Started: vSphere This guide is a walkthrough for deploying a BOSH director with bbl on vSphere. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config bbl creates and maintains the lifecycle of the jumpbox and BOSH director. It does not create any networks, security groups, or load balancers on vSphere. Create a Jumpbox and a BOSH Director Export environment variables. export BBL_IAAS=vsphere export BBL_VSPHERE_VCENTER_USER export BBL_VSPHERE_VCENTER_PASSWORD export BBL_VSPHERE_VCENTER_IP export BBL_VSPHERE_VCENTER_DC export BBL_VSPHERE_VCENTER_CLUSTER export BBL_VSPHERE_VCENTER_RP export BBL_VSPHERE_NETWORK export BBL_VSPHERE_VCENTER_DS export BBL_VSPHERE_SUBNET_CIDR export BBL_VSPHERE_VCENTER_DISKS export BBL_VSPHERE_VCENTER_TEMPLATES export BBL_VSPHERE_VCENTER_VMS or powershell: powershell $env:BBL_IAAS=\"vsphere\" $env:BBL_VSPHERE_VCENTER_USER= $env:BBL_VSPHERE_VCENTER_PASSWORD= $env:BBL_VSPHERE_VCENTER_IP= $env:BBL_VSPHERE_VCENTER_DC= $env:BBL_VSPHERE_VCENTER_CLUSTER= $env:BBL_VSPHERE_VCENTER_RP= $env:BBL_VSPHERE_NETWORK= $env:BBL_VSPHERE_VCENTER_DS= $env:BBL_VSPHERE_SUBNET_CIDR= $env:BBL_VSPHERE_VCENTER_DISKS= $env:BBL_VSPHERE_VCENTER_TEMPLATES= $env:BBL_VSPHERE_VCENTER_VMS= Create jumpbox and bosh director. bbl up Next Steps Target the BOSH Director","title":"Getting Started: vSphere"},{"location":"getting-started-vsphere/#getting-started-vsphere","text":"This guide is a walkthrough for deploying a BOSH director with bbl on vSphere. Upon completion, you will have the following: A BOSH director A jumpbox A set of randomly generated BOSH director credentials A generated keypair allowing you to SSH into the BOSH director and any instances BOSH deploys A copy of the manifest the BOSH director was deployed with A basic cloud config bbl creates and maintains the lifecycle of the jumpbox and BOSH director. It does not create any networks, security groups, or load balancers on vSphere.","title":"Getting Started: vSphere"},{"location":"getting-started-vsphere/#create-a-jumpbox-and-a-bosh-director","text":"Export environment variables. export BBL_IAAS=vsphere export BBL_VSPHERE_VCENTER_USER export BBL_VSPHERE_VCENTER_PASSWORD export BBL_VSPHERE_VCENTER_IP export BBL_VSPHERE_VCENTER_DC export BBL_VSPHERE_VCENTER_CLUSTER export BBL_VSPHERE_VCENTER_RP export BBL_VSPHERE_NETWORK export BBL_VSPHERE_VCENTER_DS export BBL_VSPHERE_SUBNET_CIDR export BBL_VSPHERE_VCENTER_DISKS export BBL_VSPHERE_VCENTER_TEMPLATES export BBL_VSPHERE_VCENTER_VMS or powershell: powershell $env:BBL_IAAS=\"vsphere\" $env:BBL_VSPHERE_VCENTER_USER= $env:BBL_VSPHERE_VCENTER_PASSWORD= $env:BBL_VSPHERE_VCENTER_IP= $env:BBL_VSPHERE_VCENTER_DC= $env:BBL_VSPHERE_VCENTER_CLUSTER= $env:BBL_VSPHERE_VCENTER_RP= $env:BBL_VSPHERE_NETWORK= $env:BBL_VSPHERE_VCENTER_DS= $env:BBL_VSPHERE_SUBNET_CIDR= $env:BBL_VSPHERE_VCENTER_DISKS= $env:BBL_VSPHERE_VCENTER_TEMPLATES= $env:BBL_VSPHERE_VCENTER_VMS= Create jumpbox and bosh director. bbl up","title":"Create a Jumpbox and a BOSH Director"},{"location":"getting-started-vsphere/#next-steps","text":"Target the BOSH Director","title":"Next Steps"},{"location":"howto-ssh/","text":"How To SSH To the Jumpbox This command shells out to ssh to initiate an interactive ssh session to the jumpbox vm. bbl ssh --jumpbox To the BOSH Director This command will shell out to ssh twice. On the first invocation, it will open a tunnel forwarding a random port to the jumpbox. On the second invocation, it initiates an interactive ssh session through that port to ssh to the director. bbl ssh --director To BOSH-Deployed VMs bbl print-env prints out environment variables ( BOSH_ALL_PROXY , BOSH_CLIENT , BOSH_CLIENT_SECRET , and others) that need to be exported to bosh ssh to a job vm using the bosh-cli. Evaluating the command output sets those variables in your environment. eval $(bbl print-env) bosh ssh web/0 When you run bosh ssh web/0 , the following happens: The bosh-cli parses BOSH_ALL_PROXY and determines from the ssh+socks5:// scheme that it should proxy through a jumpbox via a tunnel of its own making. The bosh-cli uses some go libraries to start a socks5 proxy on another goroutine. This socks5 proxy is backed by an ssh tunnel from your local machine to the jumpbox. The bosh-cli uses your system's openssh ssh \"ProxyCommand\" option and bsd nc -x to open an additional tunnel to web/0 through that socks5 proxy. When ssh exits after you ctrl-D or your ttyless command exits, the bosh-cli exits and the socks5 proxy stops with it. For http requests to the bosh director, the bosh-cli reads BOSH_ALL_PROXY=ssh+socks5:// and uses golang's ssh.Client.Dial in the cli's http.Client to send each http request to the director through an ssh tunnel between your local machine and the jumpbox. Troubleshooting It is not necessary to set BOSH_GW_HOST and other old-style bosh ssh variables. Unset them. The ubuntu stemcell allows a maximum of three login attempts, so ensure you do not have a lot of keys in your SSH keyring. ssh-add -D can clear them all.","title":"How To SSH"},{"location":"howto-ssh/#how-to-ssh","text":"","title":"How To SSH"},{"location":"howto-ssh/#to-the-jumpbox","text":"This command shells out to ssh to initiate an interactive ssh session to the jumpbox vm. bbl ssh --jumpbox","title":"To the Jumpbox"},{"location":"howto-ssh/#to-the-bosh-director","text":"This command will shell out to ssh twice. On the first invocation, it will open a tunnel forwarding a random port to the jumpbox. On the second invocation, it initiates an interactive ssh session through that port to ssh to the director. bbl ssh --director","title":"To the BOSH Director"},{"location":"howto-ssh/#to-bosh-deployed-vms","text":"bbl print-env prints out environment variables ( BOSH_ALL_PROXY , BOSH_CLIENT , BOSH_CLIENT_SECRET , and others) that need to be exported to bosh ssh to a job vm using the bosh-cli. Evaluating the command output sets those variables in your environment. eval $(bbl print-env) bosh ssh web/0 When you run bosh ssh web/0 , the following happens: The bosh-cli parses BOSH_ALL_PROXY and determines from the ssh+socks5:// scheme that it should proxy through a jumpbox via a tunnel of its own making. The bosh-cli uses some go libraries to start a socks5 proxy on another goroutine. This socks5 proxy is backed by an ssh tunnel from your local machine to the jumpbox. The bosh-cli uses your system's openssh ssh \"ProxyCommand\" option and bsd nc -x to open an additional tunnel to web/0 through that socks5 proxy. When ssh exits after you ctrl-D or your ttyless command exits, the bosh-cli exits and the socks5 proxy stops with it. For http requests to the bosh director, the bosh-cli reads BOSH_ALL_PROXY=ssh+socks5:// and uses golang's ssh.Client.Dial in the cli's http.Client to send each http request to the director through an ssh tunnel between your local machine and the jumpbox.","title":"To BOSH-Deployed VMs"},{"location":"howto-ssh/#troubleshooting","text":"It is not necessary to set BOSH_GW_HOST and other old-style bosh ssh variables. Unset them. The ubuntu stemcell allows a maximum of three login attempts, so ensure you do not have a lot of keys in your SSH keyring. ssh-add -D can clear them all.","title":"Troubleshooting"},{"location":"howto-target-bosh-director/","text":"How To Target The BOSH Director The easy way: bbl print-env eval $(bbl print-env) or powershell: iex $(bbl print-env | Out-String) Alternatives to bbl print-env Separate commands are available for the bbl print-env fields: $ bbl director-address https://10.0.0.6:25555 $ bbl director-username user-d3783rk $ bbl director-password p-23dah71skl $ bbl director-ca-cert -----BEGIN CERTIFICATE----- MIIDtzCCAp+gAwIBAgIJAIPgaUgWRCE8MA0GCSqGSIb3DQEBBQUAMEUxCzAJBgNV ... -----END CERTIFICATE----- You might save the CA certificate to a file: $ bbl director-ca-cert bosh.crt $ export BOSH_CA_CERT=bosh.crt bbl director-ca-cert | Out-File bosh.crt $env:BOSH_CA_CERT= bosh.crt To login: $ export BOSH_ENVIRONMENT=$(bbl director-address) $ bosh alias-env INSERT TARGET NAME $ bosh log-in Username: user-d3783rk Password: p-23dah71sk1 or powershell: $env:TARGET_NAME= example-name # Assigns a name to the created environment for easier access. $env:BOSH_ENVIRONMENT=$(bbl director-address) bosh alias-env $env:TARGET_NAME bosh log-in Now you're ready to deploy software with BOSH.","title":"How To Target The BOSH Director"},{"location":"howto-target-bosh-director/#how-to-target-the-bosh-director","text":"","title":"How To Target The BOSH Director"},{"location":"howto-target-bosh-director/#the-easy-way-bbl-print-env","text":"eval $(bbl print-env) or powershell: iex $(bbl print-env | Out-String)","title":"The easy way: bbl print-env"},{"location":"howto-target-bosh-director/#alternatives-to-bbl-print-env","text":"Separate commands are available for the bbl print-env fields: $ bbl director-address https://10.0.0.6:25555 $ bbl director-username user-d3783rk $ bbl director-password p-23dah71skl $ bbl director-ca-cert -----BEGIN CERTIFICATE----- MIIDtzCCAp+gAwIBAgIJAIPgaUgWRCE8MA0GCSqGSIb3DQEBBQUAMEUxCzAJBgNV ... -----END CERTIFICATE----- You might save the CA certificate to a file: $ bbl director-ca-cert bosh.crt $ export BOSH_CA_CERT=bosh.crt bbl director-ca-cert | Out-File bosh.crt $env:BOSH_CA_CERT= bosh.crt To login: $ export BOSH_ENVIRONMENT=$(bbl director-address) $ bosh alias-env INSERT TARGET NAME $ bosh log-in Username: user-d3783rk Password: p-23dah71sk1 or powershell: $env:TARGET_NAME= example-name # Assigns a name to the created environment for easier access. $env:BOSH_ENVIRONMENT=$(bbl director-address) bosh alias-env $env:TARGET_NAME bosh log-in Now you're ready to deploy software with BOSH.","title":"Alternatives to bbl print-env"},{"location":"known-issues/","text":"Known issues Migrating from bbl v4.x to v5.x on AWS An issue was discovered in v5.6.0 where the NAT security group rules were getting deleted, which prevents VMs deployed by BOSH from being able to access the internet. The issue is fixed in v5.10.0 and above, but the fix introduces a breaking change when migrating from v4.x where manual intervention is required in order for bbl up to succeed. If you are upgrading an existing bbl environment on AWS from v4.x to v5.x you may see an error during bbl up that looks like the following: Error: Error applying plan: 3 error(s) occurred: * aws_security_group_rule.nat_udp_rule: 1 error(s) occurred: * aws_security_group_rule.nat_udp_rule: [WARN] A duplicate Security Group rule was found on (sg-f424bc88). This may be a side effect of a now-fixed Terraform issue causing two security groups with identical attributes but different source_security_group_ids to overwrite each other in the state. See https://github.com/hashicorp/terraform/pull/2376 for more information and instructions for recovery. Error message: the specified rule peer: sg-1b20b867, UDP, from port: 0, to port: 65535, ALLOW already exists ... The fix is to manually delete the security group rules for the NAT box. Log into the AWS console Go to the Networking and Security Security Groups page Select the NAT security group ( ${env-id}-nat-security-group ) Click Inbound, then Edit, then remove all 3 security group rules Click Outboud, then Edit, then remove the 1 security group rule After doing the above, bbl up should work again. If you have previously run bbl up with version v5.0.x - v5.8.x , and you currently do not have any NAT security groups rules, run bbl plan with v5.10.x+ to generate the terraform template with the fix, and then run bbl up to apply the plan.","title":"Known issues"},{"location":"known-issues/#known-issues","text":"","title":"Known issues"},{"location":"known-issues/#migrating-from-bbl-v4x-to-v5x-on-aws","text":"An issue was discovered in v5.6.0 where the NAT security group rules were getting deleted, which prevents VMs deployed by BOSH from being able to access the internet. The issue is fixed in v5.10.0 and above, but the fix introduces a breaking change when migrating from v4.x where manual intervention is required in order for bbl up to succeed. If you are upgrading an existing bbl environment on AWS from v4.x to v5.x you may see an error during bbl up that looks like the following: Error: Error applying plan: 3 error(s) occurred: * aws_security_group_rule.nat_udp_rule: 1 error(s) occurred: * aws_security_group_rule.nat_udp_rule: [WARN] A duplicate Security Group rule was found on (sg-f424bc88). This may be a side effect of a now-fixed Terraform issue causing two security groups with identical attributes but different source_security_group_ids to overwrite each other in the state. See https://github.com/hashicorp/terraform/pull/2376 for more information and instructions for recovery. Error message: the specified rule peer: sg-1b20b867, UDP, from port: 0, to port: 65535, ALLOW already exists ... The fix is to manually delete the security group rules for the NAT box. Log into the AWS console Go to the Networking and Security Security Groups page Select the NAT security group ( ${env-id}-nat-security-group ) Click Inbound, then Edit, then remove all 3 security group rules Click Outboud, then Edit, then remove the 1 security group rule After doing the above, bbl up should work again. If you have previously run bbl up with version v5.0.x - v5.8.x , and you currently do not have any NAT security groups rules, run bbl plan with v5.10.x+ to generate the terraform template with the fix, and then run bbl up to apply the plan.","title":"Migrating from bbl v4.x to v5.x on AWS"},{"location":"upgrade/","text":"Upgrade In order to use a later version of bbl against an older bbl environment/state directory, you will need to run bbl plan before running bbl up . bbl plan just writes the latest files and state directory structure. bbl up is the applier. It will run terraform apply , bosh create-env , and bosh update-cloud-config . Example bbl5 up --lb-type cf --lb-cert cert --lb-key key --lb-domain domain.com # some time passes bbl6 plan --lb-type cf --lb-cert cert --lb-key key --lb-domain domain.com bbl6 up bbl6 destroy","title":"Upgrade"},{"location":"upgrade/#upgrade","text":"In order to use a later version of bbl against an older bbl environment/state directory, you will need to run bbl plan before running bbl up . bbl plan just writes the latest files and state directory structure. bbl up is the applier. It will run terraform apply , bosh create-env , and bosh update-cloud-config .","title":"Upgrade"},{"location":"upgrade/#example","text":"bbl5 up --lb-type cf --lb-cert cert --lb-key key --lb-domain domain.com # some time passes bbl6 plan --lb-type cf --lb-cert cert --lb-key key --lb-domain domain.com bbl6 up bbl6 destroy","title":"Example"}]}